(window.webpackJsonp=window.webpackJsonp||[]).push([[175],{766:function(e,t,o){"use strict";o.r(t);var r=o(36),a=Object(r.a)({},(function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("h1",{attrs:{id:"advanced-deployment"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#advanced-deployment"}},[e._v("#")]),e._v(" Advanced Deployment "),o("Badge",{attrs:{text:"draft",type:"error"}})],1),e._v(" "),o("h2",{attrs:{id:"prepare-to-scale"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#prepare-to-scale"}},[e._v("#")]),e._v(" Prepare to Scale")]),e._v(" "),o("p",[e._v("How do we prevent beeing throttled by Microsoft?")]),e._v(" "),o("p",[e._v("MS has many throttling rules, some documented and some not.")]),e._v(" "),o("p",[e._v("To forestall throttling, the first tactic is to do everything we can to avoid to reach limits. To do so, we’re using a rate limiter that supports clustering, an application component that acts as a proxy between SalesTim and the Microsoft Graph, that intelligently limits the number of requests to a specific rate, defined specifically for each endpoint.")]),e._v(" "),o("p",[e._v("Second level of prevention, the number of “Workers” could be increased, each worker using a specific app registration ID. This is from our experience, a great way to prevent throttling.​")]),e._v(" "),o("p",[e._v("Third level of prevention, we’re using massively the “Batch Requests” technique, that enables us to send multiple Graph requests in one batch.​")]),e._v(" "),o("p",[e._v("How could you scale the SalesTim platform?")]),e._v(" "),o("p",[e._v("Despite all the prevention techniques we may use, some SalesTim workers may be throttled for certain operations. In fact, it already happens multiple times every day at some point in our SAAS production environment, without noticeable impact for our end-users.​")]),e._v(" "),o("p",[e._v("First step is to properly handle the throttling responses headers from the Microsoft Graph, that clearly indicates (at least for most of the endpoints…) how long to wait before retrying the operation. For the endpoints that don’t support this mechanism (for instance, Teams endpoints that rely on Exchange or SharePoint as a back-end service, Planner APIs…), we’ve implemented our own retry policy based on our historical data.​")]),e._v(" "),o("p",[e._v("Of course, this tactic wouldn’t work properly without our highly resilient and distributed message queuing system.​")]),e._v(" "),o("p",[e._v("Lastly, as we’ve mentioned earlier, we always assume the Microsoft Graph may fail or respond with an inconsistent message. For instance, when we’re provisioning a new private channel in Teams, we’re always testing that its related drive is accessible before moving forward, to be sure that all the underlying services (in that case SharePoint) performed their own provisioning operations properly.​")]),e._v(" "),o("p",[e._v("These advanced consistency controls are based on our extensive experience developing production solutions for the Microsoft Graph.​")])])}),[],!1,null,null,null);t.default=a.exports}}]);